# Soccer Ball Detection and Tracking using YOLOv8

## Overview
This project implements a computer vision system for detecting and tracking a soccer ball in video sequences. The objective is to estimate the ball position frame by frame, even in challenging conditions such as missed detections or temporary occlusions.

The solution combines a YOLOv8-based object detector with a custom tracking and post-processing module that exploits temporal information and visual embeddings.

---

## Dataset

### Video Data
- Training set: 4 Full-HD clips (1920×1080)
- Test set: 2 Full-HD clips (1920×1080)

Each training video is associated with an XML annotation file containing the ball position for each frame when visible.

### Annotation Filtering
Annotations are ignored if:
- `used_in_game = 0`
- `outside = 1`

Only relevant in-game ball positions are considered.

### Track Definition
Each contiguous sequence of frames in which the ball appears within a clip is assigned a unique **track ID**.

---

## Model Selection

### YOLOv8 Medium
The YOLOv8 Medium model was selected as a trade-off between:
- Older architectures (e.g. YOLOv3), which are less performant
- Newer and larger models, which are computationally expensive and prone to overfitting given the limited dataset size

Key motivations:
- Strong performance already in the pre-trained version
- Pre-training on the COCO dataset, which includes the class *sports ball*
- Efficient inference and training times

---

## YOLOv8 Architecture Highlights

- Anchor-free detection
- Three detection scales for objects of different sizes
- C2F modules for improved feature reuse and accuracy
- SPPF module for fast multi-scale spatial pooling
- Task-Aligned Assigner (TAL) for optimal assignment between predictions and ground truth

---

## Training Strategy

### Transfer Learning
The model is fine-tuned starting from COCO pre-trained weights.

### Training Hyperparameters
- Epochs: 11  
- Batch size: 16  
- Image size: 800  
- Early stopping patience: 5  

These values were chosen to balance convergence, generalization, and computational constraints.

---

## Data Augmentation

To improve robustness and generalization, the following augmentations were applied:
- Translation: 0.5
- Vertical flip: enabled
- Mosaic augmentation
- MixUp: 0.2

Color, rotation, and scale augmentations were disabled to preserve realistic ball appearance and scene geometry.

---

## Post-processing and Tracking

### 1. Embedding-Based Bounding Box Association
To handle missed detections, an embedding-based strategy is used:

1. Extract the bounding box predicted at time *t*
2. Generate a visual embedding using a pre-trained **EfficientNet** (classification head removed)
3. Select candidate bounding boxes in frame *t+1* within a spatial neighborhood
4. Compute embeddings for candidates
5. Select the candidate minimizing cosine distance to the previous embedding

This approach exploits temporal coherence to recover missing predictions.

---

### 2. Handling Multiple Predictions
If multiple detections are produced in the same frame:
- The bounding box closest to the **average ball position over the last 10 frames** is selected

This strategy is more robust than relying solely on the last prediction and significantly reduces false positives.

---

### 3. False Positive Reduction
If the model fails to detect the ball in the current frame and in the following `future_len` frames, but the ball was detected in the previous frame, it is assumed that the ball exited the field of view.  
In this case, the last `past_erase` predictions generated by post-processing are discarded as false positives.

---

## Evaluation

### Quantitative Evaluation
- Metric: Mean Squared Error (MSE)
- Computed by comparing predicted trajectories with ground truth annotations
- Final score: **0.012053**

### Qualitative Evaluation
Visual inspection on test videos shows:
- Smooth and coherent ball trajectories
- Significant reduction of missed detections
- Effective suppression of false positives near field boundaries

---

## Technologies Used
- Python
- OpenCV
- Ultralytics YOLOv8
- EfficientNet (for embeddings)
- XML / JSON annotations
- Google Colab

---

## Conclusion
The project demonstrates that combining object detection with embedding-based temporal post-processing leads to robust and accurate soccer ball tracking. Despite the limited dataset size, the system achieves strong quantitative and qualitative results.

---

## Authors
- Alessandro Ruffolo  
- Daniele Oliveti  
Academic Year: 2024/2025  
MSc in Computer Engineering
