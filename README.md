# Soccer Ball Detection and Tracking using YOLOv8

[![Demo video](assets/demo_image.png)](assets/demo_video.mp4)


## Overview
This project implements a computer vision system for detecting and tracking a soccer ball in video sequences.  
The objective is to estimate the ball position frame by frame, even in challenging conditions such as temporary occlusions.

The solution combines a YOLOv8-based object detector with a custom post-processing module that exploits temporal information and visual embeddings.

The project was developed **in collaboration with Alessandro Ruffolo** and was **awarded first place in the university competition** associated with the course.

---

## Context

* **Course:** Computer Vision  
* **Academic Year:** 2023–2024  
* **University:** Università della Calabria  
* **Project Type:** Team project (2 members)  
* **Authors:**  
  - *Daniele Oliveti*  
  - *Alessandro Ruffolo*  
* **Achievement:**  *Winner of the course competition*


## githubContext

### Video Data
- Training set: 4 Full-HD clips (1920×1080)
- Test set: 2 Full-HD clips (1920×1080)

Each training video is associated with an XML annotation file containing the ball position for each frame when visible.



### YOLOv8 Medium

- Strong performance already in the pre-trained version
- Pre-training on the COCO dataset, which includes the class *sports ball*
- Efficient inference and training times

---



### Transfer Learning
The model is fine-tuned starting from COCO pre-trained weights.

### Training Hyperparameters
- Epochs: 11  
- Batch size: 16  
- Image size: 800  
- Early stopping patience: 5  

These values were chosen to balance convergence, generalization, and computational constraints.


## Data Augmentation

To improve robustness and generalization, the following augmentations were applied:
- Translation: 0.5
- Vertical flip: enabled
- Mosaic augmentation
- MixUp: 0.2

Color, rotation, and scale augmentations were disabled to preserve realistic ball appearance and scene geometry.

---

## Post-processing and Tracking

### 1. Embedding-Based Bounding Box Association
To handle missed detections, an embedding-based strategy is used:

1. Extract the bounding box predicted at time *t*
2. Generate a visual embedding using a pre-trained **EfficientNet** (classification head removed)
3. Select candidate bounding boxes in frame *t+1* within a spatial neighborhood
4. Compute embeddings for candidates
5. Select the candidate minimizing cosine distance to the previous embedding

This approach exploits temporal coherence to recover missing predictions.

---

### 2. Handling Multiple Predictions
If multiple detections are produced in the same frame:
- The bounding box closest to the **average ball position over the last 10 frames** is selected

This strategy is more robust than relying solely on the last prediction and significantly reduces false positives.

---

### 3. False Positive Reduction
If the model fails to detect the ball in the current frame and in the following `future_len` frames, but the ball was detected in the previous frame, it is assumed that the ball exited the field of view.  
In this case, the last `past_erase` predictions generated by post-processing are discarded as false positives.



## Evaluation

### Quantitative Evaluation
- Metric: Mean Squared Error (MSE)
- Computed by comparing predicted trajectories with ground truth annotations
- Final score: **0.012053**


## Technologies Used
- Python
- OpenCV
- Ultralytics YOLOv8
- EfficientNet (for embeddings)
- XML / JSON annotations
- Google Colab

---

## Conclusion
The project demonstrates that combining object detection with embedding-based temporal post-processing leads to robust and accurate soccer ball tracking. Despite the limited dataset size, the system achieves strong quantitative and qualitative results.

